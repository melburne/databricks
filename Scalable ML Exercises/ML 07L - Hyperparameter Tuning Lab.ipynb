{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bd6f131-a65e-4be1-b994-116510a6af9d"}}},{"cell_type":"markdown","source":["# Hyperparameter Tuning with Random Forests\n\nIn this lab, you will convert the Airbnb problem to a classification dataset, build a random forest classifier, and tune some hyperparameters of the random forest.\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lesson you:<br>\n - Perform grid search on a random forest\n - Get the feature importances across the forest\n - Save the model\n - Identify differences between scikit-learn's Random Forest and SparkML's\n \nYou can read more about the distributed implementation of Random Forests in the Spark [source code](https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/impl/RandomForest.scala#L42)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cd3fa6e-d285-4324-851b-9f251cfc6da7"}}},{"cell_type":"code","source":["%run \"../Includes/Classroom-Setup\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac22b3a0-10df-4692-9d7c-e30ca193485e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Initialized classroom variables & functions...","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Initialized classroom variables & functions..."]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets are already mounted to <b>/mnt/training</b> from <b>s3a://databricks-corp-training/common</b>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n<div>Declared various utility methods:</div>\n<li>Declared <b style=\"color:green\">untilStreamIsReady(<i>name:String</i>)</b> to control workflow</li>\n<br/>\n<div>All done!</div>\n","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n<div>Declared various utility methods:</div>\n<li>Declared <b style=\"color:green\">untilStreamIsReady(<i>name:String</i>)</b> to control workflow</li>\n<br/>\n<div>All done!</div>\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## From Regression to Classification\n\nIn this case, we'll turn the Airbnb housing dataset into a classification problem to **classify between high and low price listings.**  Our `class` column will be:<br><br>\n\n- `0` for a low cost listing of under $150\n- `1` for a high cost listing of $150 or more"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9468f116-a153-492c-9519-da80479f29fd"}}},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import col\n\nfilePath = \"dbfs:/mnt/training/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\n\nairbnbDF = (spark.read.format(\"delta\").load(filePath)\n  .withColumn(\"priceClass\", (col(\"price\") >= 150).cast(\"int\"))\n  .drop(\"price\")\n)\n\n(trainDF, testDF) = airbnbDF.randomSplit([.8, .2], seed=42)\n\ncategoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\nindexOutputCols = [x + \"Index\" for x in categoricalCols]\n\nstringIndexer = StringIndexer(inputCols=categoricalCols, outputCols=indexOutputCols, handleInvalid=\"skip\")\n\nnumericCols = [field for (field, dataType) in trainDF.dtypes if ((dataType == \"double\") & (field != \"priceClass\"))]\nassemblerInputs = indexOutputCols + numericCols\nvecAssembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"964fd58e-bc86-4273-ba67-9552ed687e15"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Why can't we OHE?\n\n**Question:** What would go wrong if we One Hot Encoded our variables before passing them into the random forest?\n\n**HINT:** Think about what would happen to the \"randomness\" of feature selection."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"651904a9-1fa1-4edc-ba02-0943876c1773"}}},{"cell_type":"markdown","source":["## Random Forest\n\nCreate a Random Forest classifer called `rf` with the `labelCol`=`priceClass`, `maxBins`=`40`, and `seed`=`42` (for reproducibility).\n\nIt's under `pyspark.ml.classification.RandomForestClassifier` in Python and `org.apache.spark.ml.classification.RandomForestClassifier` in Scala."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"657c7a1e-df3d-4145-b870-65678624e1da"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(labelCol=\"priceClass\", maxBins=40, seed=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d84067a1-095a-4d80-b747-a5f9bf364442"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Grid Search\n\nThere are a lot of hyperparameters we could tune, and it would take a long time to manually configure.\n\nLet's use Spark's `ParamGridBuilder` to find the optimal hyperparameters in a more systematic approach [Python](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.ParamGridBuilder)/[Scala](https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.ml.tuning.ParamGridBuilder).\n\nLet's define a grid of hyperparameters to test:\n  - maxDepth: max depth of the decision tree (Use the values `2, 5, 10`)\n  - numTrees: number of decision trees (Use the values `10, 20, 100`)\n\n`addGrid()` accepts the name of the parameter (e.g. `rf.maxDepth`), and a list of the possible values (e.g. `[2, 5, 10]`)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bec5d31a-0cb3-4d95-b677-5a2fcbe95bfa"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.tuning import ParamGridBuilder\n\nparamGrid = (ParamGridBuilder()\n            .addGrid(rf.maxDepth, [2, 5, 10])\n            .addGrid(rf.numTrees, [10, 20, 100])\n            .build())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52f73905-9749-49e0-ae23-b2b9759ce290"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n## Evaluator\n\nIn the past, we used a `RegressionEvaluator`.  For classification, we can use a [BinaryClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.BinaryClassificationEvaluator) if we have two classes or [MulticlassClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator) for more than two classes.\n\nCreate a `BinaryClassificationEvaluator` with `areaUnderROC` as the metric.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> [Read more on ROC curves here.](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)  In essence, it compares true positive and false positives."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b360d35a-f0aa-4a7d-8000-85bdc991bfa8"}}},{"cell_type":"code","source":["# TODO\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator = BinaryClassificationEvaluator(labelCol=\"priceClass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c58b78c8-f834-4fad-97dd-71e61c6bb795"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Cross Validation\n\nWe are going to do 3-Fold cross-validation, with `parallelism`=4, and set the `seed`=42 on the cross-validator for reproducibility.\n\nPut the Random Forest in the CV to speed up the cross validation (as opposed to the pipeline in the CV) [Python](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator)/[Scala](https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.ml.tuning.CrossValidator)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a7adccf-543b-461f-876f-8b2c2cacbb87"}}},{"cell_type":"code","source":["# TODO\n\nfrom pyspark.ml.tuning import CrossValidator\n\ncv = CrossValidator(estimator=rf, \n                    evaluator=evaluator, \n                    estimatorParamMaps=paramGrid,\n                    numFolds=3, \n                    parallelism=4, \n                    seed=42)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"369c356b-0f49-4a75-92b0-9884d4ae4f41"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Pipeline\n\nLet's fit the pipeline with our cross validator to our training data (this may take a few minutes)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"600fe21c-9a64-4b57-9001-091ce5649f63"}}},{"cell_type":"code","source":["stages = [stringIndexer, vecAssembler, cv]\n\npipeline = Pipeline(stages=stages)\n\npipelineModel = pipeline.fit(trainDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27e42259-ea37-4a33-aa56-968846f830a1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:838: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Hyperparameter\n\nWhich hyperparameter combination performed the best?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d4dd3ec-9d1f-4ab7-ae48-c6b8da4040ab"}}},{"cell_type":"code","source":["cvModel = pipelineModel.stages[-1]\nrfModel = cvModel.bestModel\n\nlist(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))\n\n# print(rfModel.explainParams())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1afe39b3-a233-4f0a-b4f9-859e46c85cf7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: [({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.8494609892340328),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.8450403538026396),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.8572368210894231),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.8794946343548473),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.8872232007414571),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.8882009830669131),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.9048881178918164),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.9142624641849966),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.9180625529465041)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: [({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.8494609892340328),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.8450403538026396),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 2,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.8572368210894231),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.8794946343548473),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.8872232007414571),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 5,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.8882009830669131),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 10},\n  0.9048881178918164),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 20},\n  0.9142624641849966),\n ({Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;maxDepth&#39;, doc=&#39;Maximum depth of the tree. (&gt;= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.&#39;): 10,\n   Param(parent=&#39;RandomForestClassifier_4ee87563ad4c&#39;, name=&#39;numTrees&#39;, doc=&#39;Number of trees to train (&gt;= 1).&#39;): 100},\n  0.9180625529465041)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Feature Importance"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a3cfcd2-932a-4910-a789-4ffe22660bdb"}}},{"cell_type":"code","source":["import pandas as pd\n\npandasDF = pd.DataFrame(list(zip(vecAssembler.getInputCols(), rfModel.featureImportances)), columns=[\"feature\", \"importance\"])\ntopFeatures = pandasDF.sort_values([\"importance\"], ascending=False)\ntopFeatures"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"febea957-3459-484e-958f-8a5724ce7345"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[14]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>bedrooms</td>\n      <td>0.156562</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>room_typeIndex</td>\n      <td>0.145999</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>accommodates</td>\n      <td>0.145594</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neighbourhood_cleansedIndex</td>\n      <td>0.094439</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>beds</td>\n      <td>0.074897</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>host_total_listings_count</td>\n      <td>0.056620</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>latitude</td>\n      <td>0.051551</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>longitude</td>\n      <td>0.039338</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>review_scores_rating</td>\n      <td>0.033169</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>number_of_reviews</td>\n      <td>0.031997</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>minimum_nights</td>\n      <td>0.029923</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>bathrooms</td>\n      <td>0.028360</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>property_typeIndex</td>\n      <td>0.027096</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cancellation_policyIndex</td>\n      <td>0.016465</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>review_scores_cleanliness</td>\n      <td>0.013874</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>review_scores_location</td>\n      <td>0.009767</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>review_scores_accuracy</td>\n      <td>0.008065</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>host_is_superhostIndex</td>\n      <td>0.007745</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>instant_bookableIndex</td>\n      <td>0.006643</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>review_scores_value</td>\n      <td>0.006014</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>review_scores_communication</td>\n      <td>0.003827</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>review_scores_checkin</td>\n      <td>0.002303</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>review_scores_rating_na</td>\n      <td>0.001572</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bed_typeIndex</td>\n      <td>0.001396</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>review_scores_accuracy_na</td>\n      <td>0.001294</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>review_scores_communication_na</td>\n      <td>0.001186</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>review_scores_checkin_na</td>\n      <td>0.001121</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>review_scores_value_na</td>\n      <td>0.001037</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>review_scores_location_na</td>\n      <td>0.000928</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>review_scores_cleanliness_na</td>\n      <td>0.000905</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>bathrooms_na</td>\n      <td>0.000222</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>bedrooms_na</td>\n      <td>0.000047</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>beds_na</td>\n      <td>0.000045</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>bedrooms</td>\n      <td>0.156562</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>room_typeIndex</td>\n      <td>0.145999</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>accommodates</td>\n      <td>0.145594</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neighbourhood_cleansedIndex</td>\n      <td>0.094439</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>beds</td>\n      <td>0.074897</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>host_total_listings_count</td>\n      <td>0.056620</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>latitude</td>\n      <td>0.051551</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>longitude</td>\n      <td>0.039338</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>review_scores_rating</td>\n      <td>0.033169</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>number_of_reviews</td>\n      <td>0.031997</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>minimum_nights</td>\n      <td>0.029923</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>bathrooms</td>\n      <td>0.028360</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>property_typeIndex</td>\n      <td>0.027096</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cancellation_policyIndex</td>\n      <td>0.016465</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>review_scores_cleanliness</td>\n      <td>0.013874</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>review_scores_location</td>\n      <td>0.009767</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>review_scores_accuracy</td>\n      <td>0.008065</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>host_is_superhostIndex</td>\n      <td>0.007745</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>instant_bookableIndex</td>\n      <td>0.006643</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>review_scores_value</td>\n      <td>0.006014</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>review_scores_communication</td>\n      <td>0.003827</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>review_scores_checkin</td>\n      <td>0.002303</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>review_scores_rating_na</td>\n      <td>0.001572</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bed_typeIndex</td>\n      <td>0.001396</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>review_scores_accuracy_na</td>\n      <td>0.001294</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>review_scores_communication_na</td>\n      <td>0.001186</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>review_scores_checkin_na</td>\n      <td>0.001121</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>review_scores_value_na</td>\n      <td>0.001037</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>review_scores_location_na</td>\n      <td>0.000928</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>review_scores_cleanliness_na</td>\n      <td>0.000905</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>bathrooms_na</td>\n      <td>0.000222</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>bedrooms_na</td>\n      <td>0.000047</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>beds_na</td>\n      <td>0.000045</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Do those features make sense? Would you use those features when picking an Airbnb rental?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ab32bcb-7bb4-40c3-a283-eff2c8ed447d"}}},{"cell_type":"markdown","source":["## Apply Model to test set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"480074f8-dd81-4341-abc4-502d8603cfa0"}}},{"cell_type":"code","source":["# TODO\n\npredDF = pipelineModel.transform(testDF)\nareaUnderROC = evaluator.evaluate(predDF)\nprint(f\"Area under ROC is {areaUnderROC:.2f}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9db94a3a-f4b3-477d-91df-9a58b2954634"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Area under ROC is 0.92\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Area under ROC is 0.92\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Save Model\n\nSave the model to `<userhome>/rf_pipeline_model`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28b838c4-57db-4f15-8f87-d60c5bf040d2"}}},{"cell_type":"code","source":["# TODO\n\npipelineModel.write().overwrite().save(userhome + \"/rf_pipeline_model\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28d5cef1-7d31-4f9f-92ad-a0f4e064718e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Sklearn vs SparkML\n\n[Sklearn RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) vs `SparkML RandomForestRegressor` [Python](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.RandomForestRegressor)/[Scala](https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.ml.regression.RandomForestRegressor).\n\nLook at these params in particular:\n* **n_estimators** (sklearn) vs **numTrees** (SparkML)\n* **max_depth** (sklearn) vs **maxDepth** (SparkML)\n* **max_features** (sklearn) vs **featureSubsetStrategy** (SparkML)\n* **maxBins** (SparkML only)\n\nWhat do you notice that is different?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c62a745-85e0-4a21-97de-8202f8f7181b"}}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c35b9f59-ee12-43d6-8cee-e2cf8edbbc88"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML 07L - Hyperparameter Tuning Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1750467221661783}},"nbformat":4,"nbformat_minor":0}
